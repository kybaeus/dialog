{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Warning\n",
    "This file is currently a work in progress. Expect instability, inconsistency, and ugly code.\n",
    "@W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"../../data\"\n",
    "\n",
    "# Delete me, eventually\n",
    "data_path = DATA_DIRECTORY + '/dialog-babi-task1/'\n",
    "training_file = data_path + 'dialog-babi-task1-API-calls-trn-workspace.txt'\n",
    "dev_file = data_path + 'dialog-babi-task1-API-calls-dev-workspace.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functional import seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initial object constructors\n",
    "class Workspace():\n",
    "    def __init__(self, tree):\n",
    "        # assert tree is array\n",
    "        self.tree = tree\n",
    "        \n",
    "    def add(address, content):\n",
    "        assert isinstance(address, (str))\n",
    "        assert isinstance(content, (str))\n",
    "        \n",
    "        def _add(tree):\n",
    "            if not isinstance(tree, (list)):\n",
    "                return tree\n",
    "            elif tree[0] == address:\n",
    "                return tree.concat([[content]])\n",
    "            else:\n",
    "                return map(tree, _add)\n",
    "        \n",
    "        return Workspace(_add(self.tree))\n",
    "\n",
    "    def update(self, action):\n",
    "        if action.what == 'INIT':\n",
    "            return Workspace(['root'])\n",
    "        elif action.what == 'MSG':\n",
    "            return self\n",
    "        elif action.what == 'ADD':\n",
    "            tmp = action.content.split(' ')\n",
    "            assert (len(tmp) == 2)\n",
    "            address = tmp[0]\n",
    "            address = tmp[1]\n",
    "            return this.add(address, content)\n",
    "        \n",
    "    # TODO: Figure out how to flattenDeep    \n",
    "    def to_words():\n",
    "        return \"NOT IMPLEMENTED YET\"\n",
    "    def to_tree():\n",
    "        return this.tree\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Action():\n",
    "    def __init__(self, who, what, content=False):\n",
    "        self.who = who\n",
    "        self.what = what\n",
    "        self.content = content\n",
    "        \n",
    "    def to_words(self):\n",
    "        return [f\"{self.who}:\", self.what] + (self.content.split(' ') if self.content else [])\n",
    "        \n",
    "    def to_string(self):\n",
    "        if self.content:\n",
    "            return f'{self.who}: {self.what} {self.content}'\n",
    "        else:\n",
    "            return f'{self.who}: {self.what}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def files_to_words(filenames):\n",
    "     return (seq(filenames)\n",
    "                .map(lambda filename: open(filename).read().split())\n",
    "                .flatten()\n",
    "                .distinct()\n",
    "                .sorted()\n",
    "                .to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def string_to_action(s):\n",
    "    who = s[0]\n",
    "    i = s.index(\" \")\n",
    "    line = s[i+1:]\n",
    "    j = line.index(\" \")\n",
    "    what = line[0:j]\n",
    "    content = line[j+1:]\n",
    "    return Action(who, what, content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def file_to_dialogs(filename):\n",
    "    init_entry = {\n",
    "        \"workspace\": Workspace([]),\n",
    "        \"action\": Action(who='A', what='INIT')\n",
    "    }\n",
    "    \n",
    "    action_list = [init_entry]\n",
    "    current_workspace = init_entry[\"workspace\"]\n",
    "    \n",
    "    for line in open(filename, 'r'):\n",
    "        line = line.split('\\n')\n",
    "        for dialog in line:\n",
    "            #line = line[:-1]\n",
    "            if not dialog:\n",
    "                continue\n",
    "            try: \n",
    "                action_list.append({\"workspace\": current_workspace,\n",
    "                                    \"action\": string_to_action(dialog)})\n",
    "            except ValueError:\n",
    "                print(\"This shouldn't happen!\")\n",
    "                return\n",
    "\n",
    "    return action_list\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: ADD root cuisine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open(training_file, 'r'):\n",
    "    line = line.split('\\n')\n",
    "    for dialog in line:\n",
    "        print(dialog)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "special_words = [\n",
    "  '^', '$',            # start/end markers\n",
    "  'INIT', 'WAIT',      # action types not in data\n",
    "  'NO_OUTPUT',         # filler when copy or match word is not available\n",
    "  'NO_USER_ACTION',    # initial value of lastUserAction\n",
    "  'NO_WORKSPACE_WORD'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def load_babi_data():\n",
    "    data_path = DATA_DIRECTORY + '/dialog-babi-task1/'\n",
    "    training_file = data_path + 'dialog-babi-task1-API-calls-trn-workspace.txt'\n",
    "    dev_file = data_path + 'dialog-babi-task1-API-calls-dev-workspace.txt'\n",
    "    types_and_tokens = [\n",
    "            { \"type\": 'cuisine', \"tokens\": ['french', 'italian', 'british', 'spanish', 'indian'] },\n",
    "            { \"type\": 'location', \"tokens\": ['rome', 'london', 'bombay', 'paris', 'madrid'] },\n",
    "            { \"type\": 'price', \"tokens\": ['cheap', 'moderate', 'expensive'] },\n",
    "            { \"type\": 'people', \"tokens\": ['two', 'four', 'six', 'eight'] },\n",
    "        ]\n",
    "    \n",
    "    data = {\n",
    "      \"training\": file_to_dialogs(training_file),\n",
    "      \"dev\": file_to_dialogs(dev_file),\n",
    "      \"words\": files_to_words([training_file]) + special_words,\n",
    "      \"types_and_tokens\": types_and_tokens\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_one_hot(vocab_size):\n",
    "    return ([[int(i == j) for i in range(vocab_size)] for j in range(vocab_size)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = len(data[\"words\"])\n",
    "one_hot = create_one_hot(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def action_to_one_hot(action):\n",
    "    return ((seq(['^'] + action.to_words() + ['$'])\n",
    "                .map(lambda w: data['words'].index(w))\n",
    "                .map(lambda i: one_hot[i])\n",
    "                .to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_TENSOR_SIZE = 23 #TODO: Refactor to determine automatically\n",
    "def pad_tensor(tensor):\n",
    "    m = MAX_TENSOR_SIZE\n",
    "    a = tensor\n",
    "    return a + [([0 for i in range(vocab_size)]) for j in range(m - len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_training_data(data):\n",
    "    return (seq(data)\n",
    "                .map(lambda a: a['action'])\n",
    "                .map(lambda a: action_to_one_hot(a))\n",
    "                .map(pad_tensor)\n",
    "                .map(torch.Tensor)\n",
    "           )\n",
    "\n",
    "                #.map(action_to_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A: MSG any preference on a type of cuisine'"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_babi_data()\n",
    "\n",
    "# Ensure it looks ok\n",
    "data['training'][100][\"action\"].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert our data into a list of tensors\n",
    "\n",
    "out = torch.stack(list(create_training_data(data['training'])))\n",
    "training_data = torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files_to_dialogs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-475-03300cb1837f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles_to_dialogs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'files_to_dialogs' is not defined"
     ]
    }
   ],
   "source": [
    "files_to_dialogs(training_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# WARNING!\n",
    "Everything below this cell is currently non-functional. If it compiles, I'll be rather surprised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "# TODO: Implement make OneHot\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, x_size, h_size, n_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.h_size = h_size\n",
    "        self.cell = nn.GRU(x_size, h_size)\n",
    "\n",
    "    # x: input\n",
    "    # h: hidden state\n",
    "    def forward(self, x, h):\n",
    "        for i in range(self.n_layers):\n",
    "            output, h = self.cell(output, h)\n",
    "        return output, h\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1, 1, self.h_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecoderMock(nn.Module):\n",
    "    def __init__(self, x_size, h_size, n_layers=1):\n",
    "        super(DecoderMock, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.h_size = h_size\n",
    "       #self.cell = nn.GRU(x_size, h_size)\n",
    "\n",
    "    # x: input\n",
    "    # h: hidden state\n",
    "    def forward(self):\n",
    "        for i in range(self.n_layers):\n",
    "            output, h = self.cell(output, h)\n",
    "        return output, h\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1, 1, self.h_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list(Encoder(10, 10).parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement initialization\n",
    "\n",
    "\n",
    "# Whether this is a good idea is still in question\n",
    "attentional_net = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(2, 1),\n",
    "                    torch.nn.Tanh())\n",
    "\n",
    "# Whether this is a good idea is still in question\n",
    "decoder_output_net = torch.nn.Sequential(\n",
    "                        torch.nn.Softmax())\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, x_size, h_size, n_layers=1):\n",
    "        self.n_layers = n_layers\n",
    "        self.h_size = h_size\n",
    "        self.cell = nn.GRU(x_size, h_size)\n",
    "\n",
    "        self.out = nn.Linear(h_size, )\n",
    "        self.attention = torch.nn.Sequential(torch.nn.Linear(2 * x_size, 1),\n",
    "                                             torch.nn.Tanh())\n",
    "\n",
    "    def forward(self, decoder_state, encoder_states):\n",
    "        # Combine State\n",
    "        combinedState = lambda encoder_state, z: self.attention(torch.cat(decoder_state, encoder_state), 0)\n",
    "\n",
    "        # This is terrible and I feel dirty\n",
    "        zero_states = torch.zeros(encoder_states.size()[0])\n",
    "\n",
    "        # Create attention vector\n",
    "        attention_vector = T.softmax(torch.Tensor.map_(encoder_states, zero_states,\n",
    "                                                       combinedState))\n",
    "\n",
    "        final = encoder_states * torch.transpose(attention_vector.unsqueeze(0), 0, 1).expand(encoder_states.size())\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output, h = self.cell(output, h)\n",
    "        return output, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_one_hot(vocab_size):\n",
    "    return ([[int(i == j) for i in range(vocab_size)] for j in range(vocab_size)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "Pytorch (WIP).ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
